import requests
from bs4 import BeautifulSoup
# 使用 csv package
import csv

headers = {'user-agent': 'Mozilla/5.0 (Macintosh Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}

target_url = 'https://news.cnyes.com/news/cat/headline?exp=a';

result = requests.get(target_url, headers=headers)

bs = BeautifulSoup(result.text,'html.parser')

blocks = bs.findAll("a", {"class" : "_1Zdp"})

content_urls = []
for block in blocks:
    path = block.get('href')
    content_url = 'https://news.cnyes.com' + path
    content_urls.append(content_url)

# 檔案名稱的變數
output_file_name = 'cnyes1.csv'

with open(output_file_name, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    # 先寫入 title, content 當標題
    writer.writerow(['標題', 'content'])
    
    # 把每一頁的資料撈出來
    for url in content_urls:
        result = requests.get(url, headers=headers)
        bs = BeautifulSoup(result.text,'html.parser')
        title = bs.find('h1').text
        content = bs.find("div", {"class" : "_2E8y"}).text
        # 每一頁爬到的 title, content 寫入
        writer.writerow([title, content])
